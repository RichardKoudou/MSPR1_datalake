# Projet de PrÃ©dictionÂ Ã‰lectoraleÂ â€“ POC

> Travail rÃ©alisÃ© dans le cadre de la MSPR Â«â€¯Data Lake & IAâ€¯Â». Pour le cahier des charges dÃ©taillÃ©, consultez le [sujet](Subject.md).

---

## âœ¨ Objectif

Mettre en place une **preuve de concept** pour **Elexxion**, jeune pousse spÃ©cialisÃ©e dans le conseil Ã©lectoral, capable deâ€¯:

1. Collecter puis normaliser des donnÃ©es publiques (INSEE, data.gouv, etc.) ou **gÃ©nÃ©rer des donnÃ©es factices** pour accÃ©lÃ©rer les tests.
2. Croiser ces donnÃ©es avec les rÃ©sultats Ã©lectoraux historiques.
3. EntraÃ®ner un modÃ¨le supervisÃ© afin de **prÃ©dire le bloc vainqueur** Ã Â +1,Â +2 etÂ +3Â ans.
4. Visualiser indicateurs, corrÃ©lations et projections futures.

---

## ğŸ—‚ï¸ Arborescence du dÃ©pÃ´t

```text
.
â”œâ”€â”€ assets/                # diagrammes, jeu de communes, gÃ©ojsonâ€¦
â”‚Â Â  â”œâ”€â”€ architecture.png
â”‚Â Â  â”œâ”€â”€ architecture2.png
â”‚Â Â  â””â”€â”€ communes.csv
â”œâ”€â”€ init-scripts/          # scripts SQL pour provisionner PostgreSQL
â”œâ”€â”€ src/
â”‚Â Â  â”œâ”€â”€ ingestion/         # loaders + orchestration (mode API ou Fake)
â”‚Â Â  â”œâ”€â”€ transformation/    # transformers & fusion
â”‚Â Â  â”œâ”€â”€ prediction/        # entraÃ®nement + prÃ©dicteur
â”‚Â Â  â””â”€â”€ visualization/     # graphiques et cartes
â”œâ”€â”€ notebooks/             # analyses exploratoires
â”œâ”€â”€ test/                  # tests unitaires (pytest)
â”œâ”€â”€ config.yml             # active le mode `api` ou `fake`
â”œâ”€â”€ main.py                # CLI dâ€™orchestration (ingest â†’ train â†’ predictâ€¦)
â”œâ”€â”€ docker-compose.yml     # servicesÂ : PostgreSQL, MinIO, Kafkaâ€¦
â””â”€â”€ requirements.txt       # dÃ©pendances Python
```

> **NouveautÃ©**Â : la CLI expose le switch `--mode fake|api` pour alterner entre donnÃ©es factices et rÃ©elles.

---

## ğŸ”„ Pipeline de traitement

1. Avec Dataiku DSS,

![Architecture du Projet](assets/architecture.png)
  
2. Avec des scripts Python  

```mermaid
graph LR
    subgraph 1[Ingestion]
        A1["Â«Â LoadersÂ Â» '(elections, socio_ecoâ€¦)'"] -->|Parquet| A2[data/raw]
    end

    subgraph 2[Transformation]
        A2 --> B1[Transformers]
        B1 -->|Parquet| B2[data/curated]
    end

    subgraph 3[ModÃ©lisation]
        B2 --> C1[Training Pipeline]
        C1 -->|joblib| C2[models/]
        C2 --> C3[Predictor]
    end

    subgraph 4[Visualisation]
        B2 --> D1[Heatmaps/Maps]
        C3 --> D2[Projections +1/+2/+3]
    end
```

---

## âš™ï¸ Lancer le projet

### 1. PrÃ©requis

* Docker â‰¥Â 24 (pour la stack optionnelle KafkaÂ / MinIOÂ / PostgreSQL)
* PythonÂ 3.11 (ou crÃ©ez unÂ venv)

### 2. Installation rapide

```bash
# clonage
$ git clone <url-du-repo>
$ cd mspr1_elexxion

# dÃ©pendances
$ python3 -m venv .venv && source .venv/bin/activate
$ pip install -r requirements.txt

# servicesÂ â€“ optionnels
$ docker-compose up -d   # dÃ©tachable
```

### 3. ExÃ©cution du pipeline

Mode **donnÃ©es factices** (le plus rapide pour tester lâ€™enchaÃ®nement complet)Â :

```bash
$ python main.py --step all --mode fake
```

Vous devriez obtenirÂ :

```
âœ… electionsÂ â€“ 5â€¯000Â lignes
âœ… socio_ecoÂ â€“ 36â€¯000Â lignes
âœ… communesÂ  â€“ 12â€¯000Â lignes
âœ… Transformation terminÃ©e : (36â€¯000, â€¦)
AccuracyÂ : 0.81
```

Mode **API**Â (pousse les loaders vers les sources rÃ©elles dÃ©clarÃ©es dans `config.yml`)Â :

```bash
$ python3 main.py --step ingest --mode api  # puis --step transform, trainâ€¦
```

### 4. Tests unitaires

```bash
$ pytest -q   # ingestion, transformation, prÃ©diction
```

---

## ğŸ› ï¸ Pile technologique

| Couche              | Outils principaux                       |
| ------------------- | --------------------------------------- |
| ETL                 | PythonÂ 3.11Â Â· PandasÂ Â· FakerÂ Â· Requests |
| Stockage            | Parquet (Datalake MinIO)Â Â· PostgreSQL   |
| ModÃ©lisation        | Scikitâ€‘learn (RandomForest)             |
| Viz                 | MatplotlibÂ Â· Geopandas                  |
| Orchestration       | DockerÂ Â· dockerâ€‘compose                 |
| Streaming optionnel | ApacheÂ Kafka                            |

---

## ğŸ¤ Contribution

Ce projet est dÃ©veloppÃ© dans le cadre d'un travail d'Ã©quipe de 4-5 Ã©tudiants. Pour contribuer :

1. Forkez le repository.
2. CrÃ©ez une nouvelle branche : `git checkout -b feature/nom-de-la-fonctionnalitÃ©`.
3. Faites vos modifications et commit : `git commit -m 'Ajout de la fonctionnalitÃ© X'`.
4. Poussez vers la branche : `git push origin feature/nom-de-la-fonctionnalitÃ©`.
5. Ouvrez une Pull Request.

---

## Licence

Ce dÃ©pÃ´t est fourni dans le cadre dâ€™un exercice acadÃ©miqueâ€¯; la licence par dÃ©faut est **MIT**.
