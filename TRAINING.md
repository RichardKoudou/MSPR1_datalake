# üìà Guide d‚Äôutilisation ‚Äì Phase *Training*

Ce document explique comment entra√Æner (ou r√©-entra√Æner) le mod√®le de pr√©diction √©lectorale et o√π retrouver les artefacts produits.  
Il s‚Äôappuie sur les scripts fournis dans `src/prediction/`.

---

## 1. Pr√©-requis

| √âl√©ment | Version conseill√©e |
|---------|-------------------|
| Python  | ‚â• 3.9 |
| pip     | ‚â• 23 |
| Packages | list√©s dans `requirements.txt` |

Installez-les :

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
```

---

## 2. Pr√©paration des donn√©es

Le mod√®le attend le *dataset* fusionn√© **curated** produit par la pipeline ETL.

```bash
# 1) collecte (fake ou api)
python main.py --step ingest --mode fake   # ou --mode api

# 2) transformation + fusion
python main.py --step transform
```

V√©rifiez qu‚Äôun fichier est pr√©sent :

```
data/curated/dataset.parquet
```

---

## 3. Lancer l‚Äôentra√Ænement

```bash
python main.py --step train
```

### Que se passe-t-il ?

| √âtape | D√©tails |
|-------|---------|
| **Lecture** | `data/curated/dataset.parquet` |
| **Pr√©-processing** | - Standardisation des variables num√©riques  <br>- One-hot encoding des variables cat√©gorielles |
| **Mod√®le** | `RandomForestClassifier(n_estimators=500, random_state=42)` |
| **√âvaluation** | *train / test split* 80 / 20, metrics scikit-learn |
| **Sauvegarde** | - `models/electoral_model.joblib`  *(binaire entra√Æn√©)* <br>- `models/metrics.txt`              *(accuracy + classification report)* |

Exemple de sortie :

```
‚úÖ  Mod√®le enregistr√© ‚Üí models/electoral_model.joblib
‚ÑπÔ∏è  Accuracy : 0.814 (d√©tails dans models/metrics.txt)
```

---

## 4. Lire les m√©triques

```bash
cat models/metrics.txt
```

```
Accuracy : 0.814

              precision    recall  f1-score   support
...
```

> **Astuce :** ajoutez `src/prediction/feature_importance.py` pour tracer les 15 variables les plus explicatives.

---

## 5. Personnaliser l‚Äôentra√Ænement

- **Hyper-param√®tres**  
  Modifiez la section `RandomForestClassifier(...)` dans `src/prediction/training_pipeline.py`.
- **Jeu de donn√©es diff√©rent**  
  Remplacez la constante `DATA` ou passez un chemin alternatif (TODO : ajouter un argument CLI).
- **Reproductibilit√©**  
  Changez le `random_state` ou le `seed` des loaders pour tester la robustesse.

---

## 6. D√©pannage rapide

| Probl√®me | Cause probable | Solution |
|----------|----------------|----------|
| `FileNotFoundError: dataset.parquet` | √âtapes ETL non ex√©cut√©es | Relancer `python main.py --step ingest --mode ‚Ä¶ && python main.py --step transform` |
| `ImportError: ...` | D√©pendance manquante | `pip install -r requirements.txt` |
| Accuracy tr√®s basse | ‚Äî Mod√®le sous-apprend <br>‚Äî Donn√©es simul√©es trop bruit√©es | - Tester d‚Äôautres mod√®les <br>- Ajuster le param√®tre `fake_rows` ou passer en mode *api* |

---

## 7. √âtape suivante : pr√©dictions

Une fois le mod√®le entra√Æn√©, g√©n√©rez des scores :

```bash
python main.py --step predict           # sur le jeu complet
# ou
python main.py --step predict --input data/curated/mon_fichier.parquet --output results.csv
```

Consultez ensuite `data/predictions/‚Ä¶csv` ou le fichier de sortie choisi.

---

*Bon entra√Ænement !*